---
title: "AD2 2016.2 - Lab4 - Parte 1"
author: "Rayff Queiroga"
date: "22 de março de 2017"
output: 
    html_document:
      toc: true
      toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, set.seed(825))

library(dplyr)
library(reshape2)
library(GGally)
library(ggplot2)
library(corrplot)
library(caret)
library(rpart)

```

# Bibliotecas Utlizadas

Primeiramente vamos importar as bibliotecas necessárias para esse script ser executado.

``` {r eval=FALSE, echo=TRUE}

library(dplyr)
library(reshape2)
library(GGally)
library(ggplot2)
library(corrplot)
library(caret)

```

# Descrição da atividade

Este problema tem por objetivo exercitar os conceitos sobre sistema de recomendação vistos em sala. O cenário de recomendação é o seguinte:

Um aluno (e.g. do quarto período relativo) vai realizar sua matrícula. Nesse momento, o sistema realiza uma predição das notas das disciplinas disponíveis para matrícula desse aluno.

A ideia é usar filtragem colaborativa baseada no usuário para:

  * Encontrar os alunos mais similares, em termos de disciplinas cursadas e notas tiradas nessas disciplinas, aos usuários-alvo da recomendação;
  * A partir desses vizinhos realizar as predições de notas das disciplinas disponíveis para matrícula.

# 0. Antes...

## 0.1 Funções auxiliares e variáveis globais

Para preparar e transformar os dados foram usadas as funções e variáveis auxiliares apresentadas nesta seção.

``` {r}

COL_DADOS = c("matricula", "ano", "periodo", "AL", "AV", "C1", "C2", "ES", "EDA", 
              "FC", "FM", "GI", "IC", "LEDA", "LOAC", "LP1", "LP2", "LPT", "LM",
              "MD", "ME", "OAC", "PLP", "PE", "P1", "P2", "SI1", "TC", "TG")

COL_QUARTO_PER = c("EDA", "GI", "LEDA", "ME", "PE", "PLP", "TC")


# -------------------- Collaborative Filtering -------------------------------

K = 10

# retorna uma matriz de correlação usando cor. de pearson
get_sim <- function(df) {

  row.names(df) <- df$matricula
  df <- df %>% subset(select=-c(matricula))
  
  inv_df <- as.data.frame(t(df))
  
  res <- cor(inv_df[sapply(inv_df, is.numeric)], use="p", method='pearson')
  return(res);
}

# retorna um vector de Named num, cujo nome é a matrícula e o valor a similaridade
get_neigh <- function(df, index, corr) {
  
  matr <- df[index, 1]
  
  # todos os vizinhos, porém temos que "invalidar" ele mesmo
  corr[matr, matr] = 0
  all_neigh <- corr[matr, ]
  
  k_neigh <- sort(all_neigh, decreasing = T)[1:K]
  
  return(k_neigh);
}

# calcula score ignorando vizinhos com NAs
get_score <- function(df, k_neigh) {
    
    notas <- subset(df, matricula %in% names(k_neigh))
    
    notas$sim <- 0
    for(i in 1:length(notas$matricula)) {
      notas$sim[i] <- k_neigh[as.character(notas$matricula[i])] 
    }
    
    #notas$EDA[is.na(notas$EDA)] <- 0
    notas <- na.omit(notas)
    notas$EDA <- as.numeric(notas$EDA)
    res <- sum(notas$EDA * notas$sim) / sum(notas$sim)
    return(res)
}


```

## 1. Recebendo e preparando os dados

Para preparação dos dados foi tomada a seguinte decisão: 5% dos dados serão escolhidos como dados de teste e portanto os valores das suas notas originais foram salvas para serem comparadas com a predição.

``` {r eval=TRUE, echo=TRUE}

# recebe dados
dados <- read.csv('~/DataAnalysis2/lab4/data.csv')

# remove NAs
# dados <- na.omit(dados)

# renomeando colunas
colnames(dados) <- COL_DADOS

# separando em teste e treino
temp <- createDataPartition(dados$ano, p = 0.95, list = F)

# removendo colunas de ano e período
dados <- dados %>% subset(select=-c(ano, periodo))

# os dados de teste são zerados
teste <- dados
for(i in 1:length(COL_QUARTO_PER)) {
  teste[-temp,][COL_QUARTO_PER[i]] <- 0;
}

teste_valores <- teste[-temp, ]
teste_indices <- rownames(teste_valores)
```

# 2. Encontrar os alunos mais similares, em termos de disciplinas cursadas e notas tiradas nessas disciplinas, aos usuários-alvo da recomendação;

```{r}

# calcula todas as similaridades entre todos os alunosdf 
corr <- teste %>% get_sim()

# calcula previsão: média ponderada dos K vizinhos mais próximos
for(i in 1:length(teste_indices)) {
  
  index <- teste_indices[i]
  k_proximos <- get_neigh(teste, index, corr);
  
  for(i in 1:length(COL_QUARTO_PER)) {
    previsao <- get_score(teste[, c("matricula", COL_QUARTO_PER[i])], k_proximos);
    teste[index, COL_QUARTO_PER[i]] <- previsao
  }

}

## define a function that does the calculations 
## (the covariance of two vectors divided by the square root of 
## the products of their variances is just a correlation) 
rF <- function(x, a, b) cor(x[a], x[b], use = "complete.obs") 

set.seed(1) 
bigdata <- matrix(rnorm(271 * 13890), ncol = 271) 

results <- apply(bigdata, 1, FUN = rF, a = 174:213, b = 214:253) 

## combine 
bigdata <- cbind(bigdata, iecorr = results) 


corr <- dados %>% get_sim()


```



# Referências

[1. Desbalanceamento 1](http ://www.win-vector.com/blog/2015/02/does-balancing-classes-improve-classifier-performance/)

[2. Desbalanceamento 2](https://www.r-bloggers.com/unbalanced-data-is-a-problem-no-balanced-data-is-worse/)

[3. Desbalanceamento 3](https://www.analyticsvidhya.com/blog/2016/03/practical-guide-deal-imbalanced-classification-problems/)

[4. random forest](https://en.wikipedia.org/wiki/Random_forest)

[5. random forest in R](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)

[6. Kappa](https://en.wikipedia.org/wiki/Cohen's_kappa)